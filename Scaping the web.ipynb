{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we will get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get HTML of a book page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.bookdepository.com/Machine-Learning-Kevin-P-Murphy/9780262018029?ref=grid-view&qid=1602139258108&sr=1-1\"\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name of the book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning : A Probabilistic Perspective'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find(\"h1\", {\"itemprop\":\"name\"}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin P. Murphy\n"
     ]
    }
   ],
   "source": [
    "authors = bs.find_all(\"span\", {\"itemprop\":\"author\"})\n",
    "for author in authors:\n",
    "    print(author.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image of the book's cover**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/mid/9780/2620/9780262018029.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "item_image = bs.find(\"div\", {\"class\":\"item-img\"})\n",
    "img_url = item_image.find(\"img\")[\"src\"]\n",
    "Image(url=img_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find(\"span\", {\"itemprop\":\"ratingValue\"}).get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span itemprop=\"numberOfPages\">1104 pages\n",
       "</span>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find(\"span\", {\"itemprop\":'numberOfPages'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other info: format, dimension, publisher....etc.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: Hardback                                    | 1104 pages\n",
      "Dimensions: 203                                    x 229                                    x 41mm                                                                    | 1,905g\n",
      "Publication date: 18 Oct 2016\n",
      "Publisher: MIT Press Ltd\n",
      "Imprint: MIT Press\n",
      "Publication City/Country: Cambridge, United States\n",
      "Language: English\n",
      "Illustrations note: 300 color illus., 165 b&w illus.; 465 Illustrations, unspecified\n",
      "ISBN10: 0262018020\n",
      "ISBN13: 9780262018029\n",
      "Bestsellers rank: 41,210\n"
     ]
    }
   ],
   "source": [
    "biblio_wrap = bs.find(\"div\", {\"class\":'biblio-wrap'})\n",
    "d = {}\n",
    "for item in biblio_wrap.find_all(\"li\"):\n",
    "    label = item.label.get_text()\n",
    "    info = item.span.get_text().strip().replace(\"\\n\", \"\")\n",
    "    d[label] = info\n",
    "    print(label + \": \" + info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardback                                    | 1104 pages\n",
      "18 Oct 2016\n",
      "MIT Press Ltd\n",
      "Cambridge, United States\n",
      "203                                    x 229                                    x 41mm                                                                    | 1,905g\n",
      "English\n",
      "0262018020\n",
      "9780262018029\n"
     ]
    }
   ],
   "source": [
    "bibli_info = [\"Format\", \"Publication date\", \"Publisher\", \"Publication City/Country\",\n",
    "              \"Dimensions\", \"Language\", \"ISBN10\", \"ISBN13\"]\n",
    "for i in bibli_info:\n",
    "    print(d[i].strip().replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.find(\"span\", {\"class\":\"sale-price\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "from bs4 import BeautifulSoup\n",
    "    \n",
    "\n",
    "def get_book_info(url):\n",
    "    \n",
    "    # get the html page\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        return None\n",
    "    else:\n",
    "        bs = BeautifulSoup(html.read(), \"lxml\")\n",
    "    \n",
    "    info_storage = {}\n",
    "    \n",
    "    # get book's name\n",
    "    try:\n",
    "        name = bs.find(\"h1\", {\"itemprop\":\"name\"}).get_text()\n",
    "    except:\n",
    "        name = None\n",
    "    info_storage[\"Name\"] = name\n",
    "    \n",
    "    # get authors\n",
    "    try:\n",
    "        authors = bs.find_all(\"span\", {\"itemprop\":\"author\"})\n",
    "    except:\n",
    "        author_list = None\n",
    "    else:\n",
    "        author_list = []\n",
    "        for author in authors:\n",
    "            try:\n",
    "                a = author.get_text()\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                if a:\n",
    "                    author_list.append(a.strip())\n",
    "                else:\n",
    "                    author_list.append(a)\n",
    "    info_storage[\"Authors\"] = \", \".join(author_list)\n",
    "    \n",
    "    # get price\n",
    "    try:\n",
    "        price = bs.find(\"span\", {\"class\":\"sale-price\"})\n",
    "    except:\n",
    "        price = None\n",
    "    else:\n",
    "        try:\n",
    "            price = price.get_text()\n",
    "        except:\n",
    "            price = None\n",
    "    info_storage[\"Price\"] = price\n",
    "        \n",
    "    \n",
    "    # get cover image url\n",
    "    try:\n",
    "        item_image = bs.find(\"div\", {\"class\":\"item-img\"})\n",
    "        img_url = item_image.find(\"img\")\n",
    "    except:\n",
    "        img_url = None\n",
    "    else:\n",
    "        try:\n",
    "            img_url = img_url[\"src\"]\n",
    "        except:\n",
    "            img_url = None\n",
    "    info_storage[\"Image-url\"] = img_url\n",
    "    \n",
    "    # get rating\n",
    "    try:\n",
    "        rating = bs.find(\"span\", {\"itemprop\":\"ratingValue\"})\n",
    "    except:\n",
    "        rating = None\n",
    "    else:\n",
    "        try:\n",
    "            rating = rating.get_text()\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        if rating:\n",
    "            rating = rating.strip()\n",
    "    info_storage[\"Rating\"] = rating\n",
    "    \n",
    "    # get number of pages\n",
    "    try:\n",
    "        pages = bs.find(\"span\", {\"itemprop\":'numberOfPages'})\n",
    "    except:\n",
    "        pages = None\n",
    "    else:\n",
    "        try:\n",
    "            pages = pages.get_text()\n",
    "        except:\n",
    "            pages = None\n",
    "        if pages:\n",
    "            pages = pages.replace(\"\\n\", \"\")\n",
    "    info_storage[\"NumberOfPages\"] = pages\n",
    "    \n",
    "    # others\n",
    "    bibli_info = [\"Format\", \"Publication date\", \"Publisher\", \"Publication City/Country\",\n",
    "                  \"Dimensions\", \"Language\", \"ISBN10\", \"ISBN13\"]\n",
    "    try:\n",
    "        biblio_wrap = bs.find(\"div\", {\"class\":'biblio-wrap'}).find_all('li')\n",
    "    except:\n",
    "        biblio_wrap = None\n",
    "    else:\n",
    "        labels = {}\n",
    "        for tag in biblio_wrap:\n",
    "            try:\n",
    "                label = tag.label.get_text()\n",
    "                info = tag.span.get_text()\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                labels[label] = info\n",
    "        \n",
    "        for item in bibli_info:\n",
    "            if item in labels:\n",
    "                info_storage[item] = labels[item]\n",
    "            else:\n",
    "                info_storage[item] = None\n",
    "            \n",
    "    \n",
    "    return info_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Machine Learning : A Probabilistic Perspective',\n",
       " 'Authors': 'Kevin P. Murphy',\n",
       " 'Price': None,\n",
       " 'Image-url': 'https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/mid/9780/2620/9780262018029.jpg',\n",
       " 'Rating': '4.35',\n",
       " 'NumberOfPages': '1104 pages',\n",
       " 'Format': '\\n                                Hardback\\n                                    | 1104 pages\\n\\n',\n",
       " 'Publication date': '18 Oct 2016',\n",
       " 'Publisher': '\\n\\n\\n                                        MIT Press Ltd\\n\\n',\n",
       " 'Publication City/Country': '\\n                                Cambridge, United States',\n",
       " 'Dimensions': '\\n                                203\\n                                    x 229\\n                                    x 41mm\\n                                \\n                                    | 1,905g\\n                                ',\n",
       " 'Language': '\\n                                English',\n",
       " 'ISBN10': '0262018020',\n",
       " 'ISBN13': '9780262018029'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.bookdepository.com/Machine-Learning-Kevin-P-Murphy/9780262018029?ref=grid-view&qid=1602139258108&sr=1-1\"\n",
    "get_book_info(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all Machine learning Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all url of book in a search page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_book_url_list(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        bs = BeautifulSoup(html.read(), \"lxml\")\n",
    "        \n",
    "    front = \"https://www.bookdepository.com\"\n",
    "    url_list = []\n",
    "    try:\n",
    "        tags = bs.find_all(\"div\", {\"class\":\"book-item\"})\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        for tag in tags:\n",
    "            book_url = front + tag.find('a')[\"href\"]\n",
    "            url_list.append(book_url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through all the search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs.find(\"li\", {\"id\":\"next-top\"}) # next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "# url with \"%\" will gives error, so I make a function to handle it.\n",
    "def get_percent_encoded(url):\n",
    "    scheme, netloc, path, query, fragment = parse.urlsplit(url)\n",
    "    path = parse.quote(path)\n",
    "    link = parse.urlunsplit((scheme, netloc, path, query, fragment))\n",
    "    return link\n",
    "\n",
    "def find_all_book(url):\n",
    "    \n",
    "    books = []\n",
    "    errors = []\n",
    "    front = \"https://www.bookdepository.com\"\n",
    "    while url:\n",
    "        urls = find_book_url_list(url)\n",
    "        for i in urls:\n",
    "            try:\n",
    "                book = get_book_info(i)\n",
    "            except UnicodeEncodeError:\n",
    "                i = get_percent_encoded(i)\n",
    "                book = get_book_info(i)\n",
    "            except:\n",
    "                errors.append(i)\n",
    "                print(i)\n",
    "            books.append(book)\n",
    "            \n",
    "        # next page\n",
    "        html = urlopen(url)\n",
    "        bs = BeautifulSoup(html.read(), \"lxml\")\n",
    "        url = bs.find(\"li\", {\"id\":\"next-top\"})\n",
    "        \n",
    "        if url:\n",
    "            url = front + url.a[\"href\"]\n",
    "\n",
    "            \n",
    "    return books, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hardback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_url = \"https://www.bookdepository.com/search?searchTerm=machine+learning+statistical+learning&searchSortBy=&category=&price=&availability=&searchLang=&format=2\"\n",
    "hardback, hardback_errors = find_all_book(hard_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardback_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardback_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paperback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_url = \"https://www.bookdepository.com/search?searchTerm=machine+learning+statistical+learning&searchSortBy=&category=&price=&availability=&searchLang=&format=1\"\n",
    "papeerback, paperback_errors = find_all_book(paper_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperback_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = hardback + papeerback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "colnames = list(books[0].keys())\n",
    "\n",
    "csv_file = \"bookprice.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=colnames)\n",
    "        writer.writeheader()\n",
    "        for book in books:\n",
    "            try:\n",
    "                writer.writerow(book)\n",
    "            except:\n",
    "                continue\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"bookprice.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
